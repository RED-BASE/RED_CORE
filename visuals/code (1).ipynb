{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (4258237819.py, line 510)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 510\u001b[39m\n",
      "\u001b[31m    \u001b[39m\u001b[31m\"                              avg_drift_model_sys.to_html(classes='table table-sm table-striped',\\n\",\u001b[39m\n",
      "                                                                                                          \n",
      "^\n",
      "\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"# Refined Monster Notebook: Interactive Per-Turn Drift Analysis (V2.1 CSV - Focused)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Visualizing the dataset from `per_turn_drift_v2.csv`, focusing on core drift metrics\\n\",\n",
    "    \"and comparisons between models and system prompts.\"\n",
    "   ],\n",
    "   \"metadata\": {}\n",
    "  },\n",
    "    \"# Refined Monster Notebook: Interactive Per-Turn Drift Analysis (V2.1 CSV - Focused)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Visualizing the dataset from `per_turn_drift_v2.csv`, focusing on core drift metrics\\n\",\n",
    "    \"and comparisons between models and system prompts.\"\n",
    "   ],\n",
    "   \"metadata\": {}\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup and Imports\"\n",
    "   ]\n",
    "  },\n",
    "\n",
    "   \"metadata\": {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import plotly.express as px\\n\",\n",
    "    \"import plotly.graph_objects as go\\n\",\n",
    "    \"from plotly.subplots import make_subplots\\n\",\n",
    "    \"import ipywidgets as widgets\\n\",\n",
    "    \"from IPython.display import display, HTML, clear_output\\n\",\n",
    "    \"import re\\n\",\n",
    "    \"from wordcloud import WordCloud\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import io\\n\",\n",
    "    \"import base64\\n\",\n",
    "    \"from collections import Counter\\n\",\n",
    "    \"import nltk\\n\",\n",
    "    \"from nltk.corpus import stopwords\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    stop_words = set(stopwords.words('english'))\\n\",\n",
    "    \"except LookupError:\\n\",\n",
    "    \"    nltk.download('stopwords')\\n\",\n",
    "    \"    stop_words = set(stopwords.words('english'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.preprocessing import MultiLabelBinarizer\\n\",\n",
    "    \"\\n\",\n",
    "    \"plotly_template = \\\"plotly_white\\\"\\n\",\n",
    "    \"print(\\\"Libraries imported.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 2. Data Loading and Enhanced Preprocessing\"\n",
    "   ],\n",
    "   \"metadata\": {}\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- Data Loading ---\\n\",\n",
    "    \"# IMPORTANT: Replace 'YOUR_ABSOLUTE_PATH_HERE' with the actual absolute path to your CSV file\\n\",\n",
    "    \"# OR ensure the relative path is correct from where your Jupyter server is running.\\n\",\n",
    "    \"csv_file_path = 'logs/summary/per_turn_drift_v2.csv' # Default relative path\\n\",\n",
    "    \"# csv_file_path = '/Users/redhat/Documents/GitHub/LLM-RED-CORE/logs/summary/per_turn_drift_v2.csv' # Example absolute path\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    df_original = pd.read_csv(csv_file_path)\\n\",\n",
    "    \"    print(f\\\"Successfully loaded '{csv_file_path}'\\\")\\n\",\n",
    "    \"except FileNotFoundError:\\n\",\n",
    "    \"    print(f\\\"ERROR: '{csv_file_path}' not found. Please check the path and ensure the file exists.\\\")\\n\",\n",
    "    \"    print(\\\"Falling back to a minimal empty DataFrame structure. Most visualizations will be empty.\\\")\\n\",\n",
    "    \"    print(\\\"Ensure your export_per_turn_drift.py script has run successfully and created the CSV.\\\")\\n\",\n",
    "    \"    # Define columns expected by the rest of the notebook to avoid KeyErrors\\n\",\n",
    "    \"    expected_cols = ['filename', 'experiment_id', 'model', 'sys_prompt_tag', 'sys_prompt_version', \\n\",\n",
    "    \"                     'usr_prompt_tag', 'mode', 'system_prompt_hash', 'user_prompt_hash', \\n\",\n",
    "    \"                     'scenario_hash', 'turn_index', 'drift_score', 'drift_notes', \\n\",\n",
    "    \"                     'user_input', 'model_output', 'rendered_prompt', 'variant_id', \\n\",\n",
    "    \"                     'prompt_header', 'containment_flags']\\n\",\n",
    "    \"    df_original = pd.DataFrame(columns=expected_cols)\\n\",\n",
    "    \"    # You could re-integrate your more complex sample data generator here if you want better fallback behavior.\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = df_original.copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Basic Cleaning & Type Conversion ---\\n\",\n",
    "    \"if not df.empty:\\n\",\n",
    "    \"    df['drift_score'] = pd.to_numeric(df['drift_score'], errors='coerce').fillna(0.0)\\n\",\n",
    "    \"    df['turn_index'] = pd.to_numeric(df['turn_index'], errors='coerce').fillna(0).astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Fill NaN for critical categorical columns\\n\",\n",
    "    \"    categorical_cols_to_fill = ['model', 'sys_prompt_tag', 'sys_prompt_version', 'usr_prompt_tag', \\n\",\n",
    "    \"                                'experiment_id', 'mode', 'variant_id', 'prompt_header', 'filename',\\n\",\n",
    "    \"                                'system_prompt_hash', 'user_prompt_hash', 'scenario_hash']\\n\",\n",
    "    \"    for col in categorical_cols_to_fill:\\n\",\n",
    "    \"        if col in df.columns:\\n\",\n",
    "    \"            df[col] = df[col].fillna(f'{col.upper()}_UNKNOWN')\\n\",\n",
    "    \"        else: # If a column might be missing from the CSV (e.g. if generated by older script)\\n\",\n",
    "    \"            df[col] = f'{col.upper()}_MISSING'\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df['user_input'] = df['user_input'].fillna('')\\n\",\n",
    "    \"    df['model_output'] = df['model_output'].fillna('')\\n\",\n",
    "    \"    df['rendered_prompt'] = df['rendered_prompt'].fillna('')\\n\",\n",
    "    \"    df['drift_notes'] = df['drift_notes'].fillna('')\\n\",\n",
    "    \"    df['containment_flags'] = df['containment_flags'].fillna('')\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"DataFrame is empty. Preprocessing skipped.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Parse `drift_notes` and `containment_flags` ---\\n\",\n",
    "    \"def parse_semi_colon_separated_string(notes_str):\\n\",\n",
    "    \"    if pd.isna(notes_str) or notes_str == '':\\n\",\n",
    "    \"        return []\\n\",\n",
    "    \"    return sorted(list(set([note.strip().lower() for note in str(notes_str).split(';') if note.strip()])))\\n\",\n",
    "    \"\\n\",\n",
    "    \"if 'drift_notes' in df.columns:\\n\",\n",
    "    \"    df['parsed_drift_notes'] = df['drift_notes'].apply(parse_semi_colon_separated_string)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    df['parsed_drift_notes'] = pd.Series([[] for _ in range(len(df))], index=df.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if 'containment_flags' in df.columns:\\n\",\n",
    "    \"    df['parsed_containment_flags'] = df['containment_flags'].apply(parse_semi_colon_separated_string)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    df['parsed_containment_flags'] = pd.Series([[] for _ in range(len(df))], index=df.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- One-Hot Encode `parsed_drift_notes` ---\\n\",\n",
    "    \"all_drift_note_tags = []\\n\",\n",
    "    \"if 'parsed_drift_notes' in df.columns:\\n\",\n",
    "    \"    all_drift_note_tags = sorted(list(set(tag for sublist in df['parsed_drift_notes'] for tag in sublist)))\\n\",\n",
    "    \"if all_drift_note_tags:\\n\",\n",
    "    \"    mlb_notes = MultiLabelBinarizer(classes=all_drift_note_tags)\\n\",\n",
    "    \"    df_notes_encoded = pd.DataFrame(mlb_notes.fit_transform(df['parsed_drift_notes']),\\n\",\n",
    "    \"                                    columns=[\\\"dnote_\\\" + c for c in mlb_notes.classes_], index=df.index)\\n\",\n",
    "    \"    df = pd.concat([df, df_notes_encoded], axis=1)\\n\",\n",
    "    \"    print(f\\\"One-hot encoded {len(mlb_notes.classes_)} drift note types.\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    mlb_notes = None\\n\",\n",
    "    \"    print(\\\"No drift notes found to one-hot encode.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- One-Hot Encode `parsed_containment_flags` ---\\n\",\n",
    "    \"all_containment_flag_tags = []\\n\",\n",
    "    \"if 'parsed_containment_flags' in df.columns:\\n\",\n",
    "    \"    all_containment_flag_tags = sorted(list(set(tag for sublist in df['parsed_containment_flags'] for tag in sublist)))\\n\",\n",
    "    \"if all_containment_flag_tags:\\n\",\n",
    "    \"    mlb_flags = MultiLabelBinarizer(classes=all_containment_flag_tags)\\n\",\n",
    "    \"    df_flags_encoded = pd.DataFrame(mlb_flags.fit_transform(df['parsed_containment_flags']),\\n\",\n",
    "    \"                                     columns=[\\\"cflag_\\\" + c for c in mlb_flags.classes_], index=df.index)\\n\",\n",
    "    \"    df = pd.concat([df, df_flags_encoded], axis=1)\\n\",\n",
    "    \"    print(f\\\"One-hot encoded {len(mlb_flags.classes_)} containment flag types.\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    mlb_flags = None\\n\",\n",
    "    \"    print(\\\"No containment flags found to one-hot encode.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nPreprocessing Complete.\\\")\\n\",\n",
    "    \"if not df.empty:\\n\",\n",
    "    \"    print(\\\"DataFrame info:\\\")\\n\",\n",
    "    \"    df.info()\\n\",\n",
    "    \"    print(\\\"\\\\nSample of processed data (first 3 rows):\\\")\\n\",\n",
    "    \"    display(df.head(3))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"DataFrame remains empty.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 3. Interactive Dashboard Setup (Focused)\"\n",
    "   ],\n",
    "   \"metadata\": {}\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- Widgets ---\\n\",\n",
    "    \"dashboard_title_v2_1 = widgets.HTML(\\\"<h1>Interactive Model Drift Explorer (V2.1 Data)</h1>\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"def create_dropdown_v2_1(column_name, description_text, default_value='All', width='auto'):\\n\",\n",
    "    \"    options = ['All']\\n\",\n",
    "    \"    if column_name in df.columns and not df.empty and df[column_name].notna().any():\\n\",\n",
    "    \"        options.extend(sorted(list(df[column_name].dropna().unique())))\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        options.append(f'{column_name.upper()}_NODATA')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if default_value not in options and options: default_value = options[0]\\n\",\n",
    "    \"    elif not options: return widgets.HTML(f\\\"<i>No options for {description_text}</i>\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return widgets.Dropdown(options=options, value=default_value, description=description_text, \\n\",\n",
    "    \"                            style={'description_width': 'initial'}, layout=widgets.Layout(width=width))\\n\",\n",
    "    \"\\n\",\n",
    "    \"model_dropdown_v2_1 = create_dropdown_v2_1('model', 'Model:')\\n\",\n",
    "    \"sys_prompt_dropdown_v2_1 = create_dropdown_v2_1('sys_prompt_tag', 'Sys Prompt:')\\n\",\n",
    "    \"usr_prompt_dropdown_v2_1 = create_dropdown_v2_1('usr_prompt_tag', 'Usr Prompt:')\\n\",\n",
    "    \"experiment_dropdown_v2_1 = create_dropdown_v2_1('experiment_id', 'Experiment:', width='500px')\\n\",\n",
    "    \"mode_dropdown_v2_1 = create_dropdown_v2_1('mode', 'Mode:')\\n\",\n",
    "    \"variant_id_dropdown_v2_1 = create_dropdown_v2_1('variant_id', 'Variant ID:')\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"min_drift_v2_1, max_drift_v2_1 = (df['drift_score'].min(), df['drift_score'].max()) if not df.empty and 'drift_score' in df.columns and df['drift_score'].notna().any() else (0.0, 1.0)\\n\",\n",
    "    \"drift_slider_v2_1 = widgets.FloatRangeSlider(\\n\",\n",
    "    \"    value=[min_drift_v2_1, max_drift_v2_1], min=min_drift_v2_1, max=max_drift_v2_1, step=0.01,\\n\",\n",
    "    \"    description='Drift Range:', continuous_update=False, style={'description_width': 'initial'}, layout=widgets.Layout(width='400px')\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"min_turn_v2_1, max_turn_v2_1 = (int(df['turn_index'].min()), int(df['turn_index'].max())) if not df.empty and 'turn_index' in df.columns and df['turn_index'].notna().any() else (1, 10)\\n\",\n",
    "    \"turn_slider_v2_1 = widgets.IntRangeSlider(\\n\",\n",
    "    \"    value=[min_turn_v2_1, max_turn_v2_1], min=min_turn_v2_1, max=max_turn_v2_1, step=1,\\n\",\n",
    "    \"    description='Turn Range:', continuous_update=False, style={'description_width': 'initial'}, layout=widgets.Layout(width='400px')\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if all_drift_note_tags:\\n\",\n",
    "    \"    dnote_filter_v2_1 = widgets.SelectMultiple(options=['All'] + all_drift_note_tags, value=['All'], description='Drift Notes:', rows=min(5, len(all_drift_note_tags)+1))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    dnote_filter_v2_1 = widgets.HTML(\\\"<i>No drift notes for filtering.</i>\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if all_containment_flag_tags:\\n\",\n",
    "    \"    cflag_filter_v2_1 = widgets.SelectMultiple(options=['All'] + all_containment_flag_tags, value=['All'], description='Contain. Flags:', rows=min(5, len(all_containment_flag_tags)+1))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    cflag_filter_v2_1 = widgets.HTML(\\\"<i>No containment flags for filtering.</i>\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"viz_options_v2_1 = ['Drift Trajectory (Model & SysPrompt vs Turn)', \\n\",\n",
    "    \"                  'Drift Distribution (Model vs SysPrompt)', \\n\",\n",
    "    \"                  'Drift Heatmap (Model & SysPrompt vs Turn)',\\n\",\n",
    "    \"                  'Drift Notes Frequency', 'Drift Notes vs Score',\\n\",\n",
    "    \"                  'Containment Flags Frequency', 'Containment Flags vs Score',\\n\",\n",
    "    \"                  'Text WordCloud (Model Output)',\\n\",\n",
    "    \"                  '3D Drift Scatter (Turn, Model/SysPrompt, Score)']\\n\",\n",
    "    \"viz_type_dropdown_v2_1 = widgets.Dropdown(options=viz_options_v2_1, value=viz_options_v2_1[0], description='View Type:')\\n\",\n",
    "    \"\\n\",\n",
    "    \"main_plot_output_v2_1 = go.FigureWidget()\\n\",\n",
    "    \"detail_text_output_v2_1 = widgets.HTML(value=\\\"<i>Click point on Trajectory/3D Scatter for details.</i>\\\", layout=widgets.Layout(height='250px', overflow_y='auto', border='1px solid #ccc', padding='10px'))\\n\",\n",
    "    \"stats_output_v2_1 = widgets.HTML(value=\\\"<i>Statistics summary.</i>\\\", layout=widgets.Layout(height='250px', overflow_y='auto', border='1px solid #ccc', padding='10px'))\\n\",\n",
    "    \"stats_button_v2_1 = widgets.Button(description=\\\"Refresh Filtered Stats\\\", button_style='info')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 4. Focused Filtering and Plotting Functions\"\n",
    "   ],\n",
    "   \"metadata\": {}\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- Focused Filtering Function ---\\n\",\n",
    "    \"def get_filtered_df_v2_1():\\n\",\n",
    "    \"    f_df = df.copy()\\n\",\n",
    "    \"    if f_df.empty: return f_df\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Apply filters only if the corresponding column exists in f_df\\n\",\n",
    "    \"    if model_dropdown_v2_1.value != 'All' and 'model' in f_df.columns: f_df = f_df[f_df['model'] == model_dropdown_v2_1.value]\\n\",\n",
    "    \"    if sys_prompt_dropdown_v2_1.value != 'All' and 'sys_prompt_tag' in f_df.columns: f_df = f_df[f_df['sys_prompt_tag'] == sys_prompt_dropdown_v2_1.value]\\n\",\n",
    "    \"    if usr_prompt_dropdown_v2_1.value != 'All' and 'usr_prompt_tag' in f_df.columns: f_df = f_df[f_df['usr_prompt_tag'] == usr_prompt_dropdown_v2_1.value]\\n\",\n",
    "    \"    if experiment_dropdown_v2_1.value != 'All' and 'experiment_id' in f_df.columns: f_df = f_df[f_df['experiment_id'] == experiment_dropdown_v2_1.value]\\n\",\n",
    "    \"    if mode_dropdown_v2_1.value != 'All' and 'mode' in f_df.columns: f_df = f_df[f_df['mode'] == mode_dropdown_v2_1.value]\\n\",\n",
    "    \"    if variant_id_dropdown_v2_1.value != 'All' and 'variant_id' in f_df.columns: f_df = f_df[f_df['variant_id'] == variant_id_dropdown_v2_1.value]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if 'drift_score' in f_df.columns: \\n\",\n",
    "    \"        f_df = f_df[(f_df['drift_score'] >= drift_slider_v2_1.value[0]) & (f_df['drift_score'] <= drift_slider_v2_1.value[1])]\\n\",\n",
    "    \"    if 'turn_index' in f_df.columns:\\n\",\n",
    "    \"        f_df = f_df[(f_df['turn_index'] >= turn_slider_v2_1.value[0]) & (f_df['turn_index'] <= turn_slider_v2_1.value[1])]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if mlb_notes and isinstance(dnote_filter_v2_1, widgets.SelectMultiple) and 'All' not in dnote_filter_v2_1.value:\\n\",\n",
    "    \"        selected_notes = dnote_filter_v2_1.value\\n\",\n",
    "    \"        note_cols_to_check = [\\\"dnote_\\\" + note for note in selected_notes]\\n\",\n",
    "    \"        valid_note_cols = [col for col in note_cols_to_check if col in f_df.columns]\\n\",\n",
    "    \"        if valid_note_cols: f_df = f_df[f_df[valid_note_cols].sum(axis=1) > 0]\\n\",\n",
    "    \"        elif selected_notes and not f_df.empty: f_df = pd.DataFrame(columns=f_df.columns) # Return empty if specific notes selected but no such columns\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if mlb_flags and isinstance(cflag_filter_v2_1, widgets.SelectMultiple) and 'All' not in cflag_filter_v2_1.value:\\n\",\n",
    "    \"        selected_flags = cflag_filter_v2_1.value\\n\",\n",
    "    \"        flag_cols_to_check = [\\\"cflag_\\\" + flag for flag in selected_flags]\\n\",\n",
    "    \"        valid_flag_cols = [col for col in flag_cols_to_check if col in f_df.columns]\\n\",\n",
    "    \"        if valid_flag_cols: f_df = f_df[f_df[valid_flag_cols].sum(axis=1) > 0]\\n\",\n",
    "    \"        elif selected_flags and not f_df.empty: f_df = pd.DataFrame(columns=f_df.columns)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"    return f_df\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Click Handler (More Robust) ---\\n\",\n",
    "    \"def handle_point_click_v2_1(trace, points, state):\\n\",\n",
    "    \"    if not points.point_inds:\\n\",\n",
    "    \"        detail_text_output_v2_1.value = \\\"<i>Click on a data point on Trajectory or 3D Scatter.</i>\\\"\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"\\n\",\n",
    "    \"    clicked_custom_data_index_in_trace = points.point_inds[0]\\n\",\n",
    "    \"    selected_row_data = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Check if customdata (original DataFrame index) was passed and retrieve it\\n\",\n",
    "    \"    if hasattr(trace, 'customdata') and trace.customdata is not None and \\\\\\n\",\n",
    "    \"       len(trace.customdata) > clicked_custom_data_index_in_trace:\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        original_df_idx = trace.customdata[clicked_custom_data_index_in_trace]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Ensure original_df_idx is a single value if it's wrapped in a list/tuple by Plotly\\n\",\n",
    "    \"        if isinstance(original_df_idx, (list, tuple)) and len(original_df_idx) == 1:\\n\",\n",
    "    \"            original_df_idx = original_df_idx[0]\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        if original_df_idx in df_original.index:\\n\",\n",
    "    \"            selected_row_data = df_original.loc[original_df_idx]\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            detail_text_output_v2_1.value = f\\\"<i>Error: Original index {original_df_idx} not found in df_original. Customdata might be misconfigured.</i>\\\"\\n\",\n",
    "    \"            return\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        # Fallback if customdata is not setup - this is less reliable\\n\",\n",
    "    \"        f_df = get_filtered_df_v2_1()\\n\",\n",
    "    \"        if not f_df.empty and clicked_custom_data_index_in_trace < len(f_df):\\n\",\n",
    "    \"            # This assumes point_inds directly map to filtered_df, which might not always hold for px.line with groups\\n\",\n",
    "    \"             clicked_row_in_filtered_df = f_df.iloc[clicked_custom_data_index_in_trace] \\n\",\n",
    "    \"             # We need filename and turn to uniquely identify in df_original\\n\",\n",
    "    \"             fname = clicked_row_in_filtered_df.get('filename')\\n\",\n",
    "    \"             t_idx = clicked_row_in_filtered_df.get('turn_index')\\n\",\n",
    "    \"             if fname is not None and t_idx is not None:\\n\",\n",
    "    \"                possible_matches = df_original[(df_original['filename']==fname) & (df_original['turn_index']==t_idx)]\\n\",\n",
    "    \"                if not possible_matches.empty:\\n\",\n",
    "    \"                    selected_row_data = possible_matches.iloc[0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if selected_row_data is not None and isinstance(selected_row_data, pd.Series):\\n\",\n",
    "    \"        details_html = f\\\"\\\"\\\"\\n\",\n",
    "    \"        <h3>Details:</h3>\\n\",\n",
    "    \"        <b>File:</b> {selected_row_data.get('filename', 'N/A')}<br>\\n\",\n",
    "    \"        <b>Experiment:</b> {selected_row_data.get('experiment_id', 'N/A')}<br>\\n\",\n",
    "    \"        <b>Model:</b> {selected_row_data.get('model', 'N/A')}<br>\\n\",\n",
    "    \"        <b>Sys Prompt:</b> {selected_row_data.get('sys_prompt_tag', 'N/A')} (v: {selected_row_data.get('sys_prompt_version', 'N/A')})<br>\\n\",\n",
    "    \"        <b>Usr Prompt:</b> {selected_row_data.get('usr_prompt_tag', 'N/A')}<br>\\n\",\n",
    "    \"        <b>Variant ID:</b> {selected_row_data.get('variant_id', 'N/A')}<br>\\n\",\n",
    "    \"        <b>Mode:</b> {selected_row_data.get('mode', 'N/A')}<br>\\n\",\n",
    "    \"        <b>Turn:</b> {selected_row_data.get('turn_index', 'N/A')}<br>\\n\",\n",
    "    \"        <b>Drift Score:</b> {selected_row_data.get('drift_score', np.nan):.3f}<br>\\n\",\n",
    "    \"        <b>Drift Notes:</b> {selected_row_data.get('drift_notes', 'N/A')}<br>\\n\",\n",
    "    \"        <b>Containment Flags:</b> {selected_row_data.get('containment_flags', 'N/A')}<br>\\n\",\n",
    "    \"        <h4>Rendered Prompt:</h4><div style='background-color:#f0f0f0; padding:5px; border:1px solid #ddd; max-height:100px; overflow-y:auto;'>{HTML(str(selected_row_data.get('rendered_prompt', ''))).value}</div>\\n\",\n",
    "    \"        <h4>Model Output:</h4><div style='background-color:#e6f3ff; padding:5px; border:1px solid #ddd; max-height:150px; overflow-y:auto;'>{HTML(str(selected_row_data.get('model_output', ''))).value}</div>\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        detail_text_output_v2_1.value = details_html\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        detail_text_output_v2_1.value = \\\"<i>Could not retrieve details for the clicked point. Ensure plots pass original index via custom_data.</i>\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Plotting Functions (Focused) ---\\n\",\n",
    "    \"def plot_drift_trajectory_focused(f_df):\\n\",\n",
    "    \"    if f_df.empty: return go.Figure().update_layout(title_text=\\\"No data for Trajectory.\\\", template=plotly_template)\\n\",\n",
    "    \"    fig = px.line(f_df, x='turn_index', y='drift_score', color='model',\\n\",\n",
    "    \"                  line_dash='sys_prompt_tag', markers=True,\\n\",\n",
    "    \"                  hover_data=['filename', 'experiment_id', 'drift_notes'],\\n\",\n",
    "    \"                  custom_data=[f_df.index], # Pass original DataFrame index\\n\",\n",
    "    \"                  title=\\\"Drift Score per Turn (Model & System Prompt)\\\", template=plotly_template)\\n\",\n",
    "    \"    fig.update_layout(height=600, legend_title_text='Model | SysPrompt')\\n\",\n",
    "    \"    for trace in fig.data:\\n\",\n",
    "    \"        if isinstance(trace, (go.Scatter, go.Scattergl)):\\n\",\n",
    "    \"             trace.on_click(handle_point_click_v2_1)\\n\",\n",
    "    \"    return fig\\n\",\n",
    "    \"\\n\",\n",
    "    \"def plot_drift_distribution_focused(f_df):\\n\",\n",
    "    \"    if f_df.empty: return go.Figure().update_layout(title_text=\\\"No data for Distribution.\\\", template=plotly_template)\\n\",\n",
    "    \"    fig = px.box(f_df, x='model', y='drift_score', color='sys_prompt_tag',\\n\",\n",
    "    \"                 title='Drift Score Distribution (Model vs System Prompt)', template=plotly_template)\\n\",\n",
    "    \"    fig.update_layout(height=600, xaxis_title='Model', yaxis_title='Drift Score', legend_title_text='System Prompt')\\n\",\n",
    "    \"    return fig\\n\",\n",
    "    \"\\n\",\n",
    "    \"def plot_drift_heatmap_focused(f_df):\\n\",\n",
    "    \"    if f_df.empty: return go.Figure().update_layout(title_text=\\\"No data for Heatmap.\\\", template=plotly_template)\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Try to pivot for a more detailed view if possible\\n\",\n",
    "    \"        if f_df['model'].nunique() > 1 and f_df['sys_prompt_tag'].nunique() > 1:\\n\",\n",
    "    \"             pivot_df = f_df.groupby(['turn_index', 'model', 'sys_prompt_tag'])['drift_score'].mean().unstack(['model', 'sys_prompt_tag'])\\n\",\n",
    "    \"             x_label = \\\"Model & System Prompt\\\"\\n\",\n",
    "    \"             y_label = \\\"Turn Index\\\"\\n\",\n",
    "    \"        elif f_df['model'].nunique() > 1:\\n\",\n",
    "    \"            pivot_df = f_df.pivot_table(values='drift_score', index='model', columns='turn_index', aggfunc=np.mean)\\n\",\n",
    "    \"            x_label = \\\"Turn Index\\\"\\n\",\n",
    "    \"            y_label = \\\"Model\\\"\\n\",\n",
    "    \"        elif f_df['sys_prompt_tag'].nunique() > 1:\\n\",\n",
    "    \"            pivot_df = f_df.pivot_table(values='drift_score', index='sys_prompt_tag', columns='turn_index', aggfunc=np.mean)\\n\",\n",
    "    \"            x_label = \\\"Turn Index\\\"\\n\",\n",
    "    \"            y_label = \\\"System Prompt\\\"\\n\",\n",
    "    \"        else: # Fallback if only one model and one sys_prompt selected (or not enough diversity)\\n\",\n",
    "    \"            pivot_df = f_df.pivot_table(values='drift_score', index='experiment_id', columns='turn_index', aggfunc=np.mean)\\n\",\n",
    "    \"            x_label = \\\"Turn Index\\\"\\n\",\n",
    "    \"            y_label = \\\"Experiment ID\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if pivot_df.empty or pivot_df.shape[1] == 0:\\n\",\n",
    "    \"            return go.Figure().update_layout(title_text=\\\"Not enough data diversity for this heatmap view.\\\", template=plotly_template)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        fig = px.imshow(pivot_df, \\n\",\n",
    "    \"                        labels=dict(x=x_label, y=y_label, color=\\\"Avg Drift Score\\\"),\\n\",\n",
    "    \"                        title='Avg Drift Heatmap', \\n\",\n",
    "    \"                        color_continuous_scale='RdYlGn_r',\\n\",\n",
    "    \"                        template=plotly_template, aspect=\\\"auto\\\")\\n\",\n",
    "    \"        fig.update_layout(height=700, xaxis_tickangle=-45 if len(pivot_df.columns) > 10 else 0)\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        fig = go.Figure().update_layout(title_text=f\\\"Error creating heatmap: {e}\\\", template=plotly_template)\\n\",\n",
    "    \"    return fig\\n\",\n",
    "    \"\\n\",\n",
    "    \"def plot_notes_or_flags_freq_v2_1(f_df, column_prefix, parsed_column_name, title_suffix):\\n\",\n",
    "    \"    if f_df.empty or parsed_column_name not in f_df.columns:\\n\",\n",
    "    \"        return go.Figure().update_layout(title_text=f\\\"No data for {title_suffix} Frequency.\\\", template=plotly_template)\\n\",\n",
    "    \"    all_items_filtered = Counter(tag for sublist in f_df[parsed_column_name] for tag in sublist)\\n\",\n",
    "    \"    if not all_items_filtered: return go.Figure().update_layout(title_text=f\\\"No {title_suffix} in selected data.\\\", template=plotly_template)\\n\",\n",
    "    \"    item_freq_df = pd.DataFrame(all_items_filtered.most_common(20), columns=[title_suffix.split()[0], 'Frequency'])\\n\",\n",
    "    \"    fig = px.bar(item_freq_df, x='Frequency', y=title_suffix.split()[0], orientation='h', title=f'Top 20 {title_suffix} Frequencies', template=plotly_template)\\n\",\n",
    "    \"    fig.update_layout(height=max(600, len(item_freq_df) * 30), yaxis={'categoryorder':'total ascending'})\\n\",\n",
    "    \"    return fig\\n\",\n",
    "    \"\\n\",\n",
    "    \"def plot_notes_or_flags_vs_score_v2_1(f_df, column_prefix, title_suffix):\\n\",\n",
    "    \"    if f_df.empty or not any(col.startswith(column_prefix) for col in f_df.columns):\\n\",\n",
    "    \"        return go.Figure().update_layout(title_text=f\\\"No data/encoded {title_suffix} for Score Comparison.\\\", template=plotly_template)\\n\",\n",
    "    \"    item_cols = [col for col in f_df.columns if col.startswith(column_prefix)]\\n\",\n",
    "    \"    if not item_cols: return go.Figure().update_layout(title_text=f\\\"No one-hot encoded {title_suffix} columns found.\\\", template=plotly_template)\\n\",\n",
    "    \"    melted_df = f_df.melt(id_vars=['drift_score'], value_vars=item_cols, var_name=f'{title_suffix} Type', value_name='Is Present')\\n\",\n",
    "    \"    melted_df = melted_df[melted_df['Is Present'] == 1]\\n\",\n",
    "    \"    melted_df[f'{title_suffix} Type'] = melted_df[f'{title_suffix} Type'].str.replace(column_prefix, '')\\n\",\n",
    "    \"    if melted_df.empty: return go.Figure().update_layout(title_text=f\\\"No {title_suffix} present for score comparison.\\\", template=plotly_template)\\n\",\n",
    "    \"    fig = px.box(melted_df, x=f'{title_suffix} Type', y='drift_score', title=f'Drift Score Distribution by {title_suffix} Type', template=plotly_template)\\n\",\n",
    "    \"    fig.update_layout(height=600, xaxis_tickangle=-45)\\n\",\n",
    "    \"    return fig\\n\",\n",
    "    \"\\n\",\n",
    "    \"def plot_wordcloud_v2_1(f_df, text_column='model_output'):\\n\",\n",
    "    \"    if f_df.empty or text_column not in f_df.columns:\\n\",\n",
    "    \"        return go.Figure().update_layout(title_text=\\\"No data for WordCloud.\\\", template=plotly_template)\\n\",\n",
    "    \"    text_corpus = \\\" \\\".join(f_df[text_column].astype(str).dropna())\\n\",\n",
    "    \"    if not text_corpus.strip(): return go.Figure().update_layout(title_text=f\\\"No text in '{text_column}' for WordCloud.\\\", template=plotly_template)\\n\",\n",
    "    \"    processed_text = text_corpus.lower()\\n\",\n",
    "    \"    processed_text = re.sub(r'[\\\\\\\"“”‘’]', '', processed_text) # Remove more quote types\\n\",\n",
    "    \"    processed_text = re.sub(r'[^\\\\w\\\\s]', ' ', processed_text) # Replace punctuation with space\\n\",\n",
    "    \"    words = [word for word in processed_text.split() if word not in stop_words and len(word) > 2 and not word.isnumeric()]\\n\",\n",
    "    \"    if not words: return go.Figure().update_layout(title_text=\\\"No significant words for Word Cloud.\\\", template=plotly_template)\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        wordcloud = WordCloud(width=800, height=500, background_color='white', colormap=\\\"viridis\\\").generate(\\\" \\\".join(words))\\n\",\n",
    "    \"        img_bytes = io.BytesIO()\\n\",\n",
    "    \"        fig_temp_wc, ax = plt.subplots(figsize=(10,6))\\n\",\n",
    "    \"        ax.imshow(wordcloud, interpolation='bilinear')\\n\",\n",
    "    \"        ax.axis('off')\\n\",\n",
    "    \"        fig_temp_wc.savefig(img_bytes, format='png', bbox_inches='tight', pad_inches=0)\\n\",\n",
    "    \"        plt.close(fig_temp_wc)\\n\",\n",
    "    \"        img_bytes.seek(0)\\n\",\n",
    "    \"        img_base64 = base64.b64encode(img_bytes.read()).decode('utf-8')\\n\",\n",
    "    \"        fig = go.Figure(go.Image(source=f'data:image/png;base64,{img_base64}'))\\n\",\n",
    "    \"        fig.update_layout(title_text=f'Word Cloud of {text_column} (Filtered)', height=600, template=plotly_template)\\n\",\n",
    "    \"        fig.update_xaxes(showticklabels=False, visible=False)\\n\",\n",
    "    \"        fig.update_yaxes(showticklabels=False, visible=False)\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        fig = go.Figure().update_layout(title_text=f\\\"Error generating wordcloud: {e}\\\", template=plotly_template)\\n\",\n",
    "    \"    return fig\\n\",\n",
    "    \"\\n\",\n",
    "    \"def plot_3d_drift_scatter_focused(f_df):\\n\",\n",
    "    \"    if f_df.empty: return go.Figure().update_layout(title_text=\\\"No data for 3D Scatter.\\\", template=plotly_template)\\n\",\n",
    "    \"    y_axis_col = 'model'\\n\",\n",
    "    \"    color_col = 'sys_prompt_tag'\\n\",\n",
    "    \"    y_title = 'Model'\\n\",\n",
    "    \"    if model_dropdown_v2_1.value != 'All' and 'sys_prompt_tag' in f_df.columns and f_df['sys_prompt_tag'].nunique() > 0:\\n\",\n",
    "    \"        y_axis_col = 'sys_prompt_tag'\\n\",\n",
    "    \"        color_col = 'usr_prompt_tag' if 'usr_prompt_tag' in f_df.columns and f_df['usr_prompt_tag'].nunique() > 0 else 'experiment_id'\\n\",\n",
    "    \"        y_title = 'System Prompt'\\n\",\n",
    "    \"    elif sys_prompt_dropdown_v2_1.value != 'All' and 'model' in f_df.columns and f_df['model'].nunique() > 0:\\n\",\n",
    "    \"        y_axis_col = 'model'\\n\",\n",
    "    \"        color_col = 'usr_prompt_tag' if 'usr_prompt_tag' in f_df.columns and f_df['usr_prompt_tag'].nunique() > 0 else 'experiment_id'\\n\",\n",
    "    \"        y_title = 'Model'\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if y_axis_col not in f_df.columns or f_df[y_axis_col].nunique() == 0:\\n\",\n",
    "    \"        return go.Figure().update_layout(title_text=f\\\"Not enough unique values for Y-axis '{y_title}' in 3D scatter.\\\", template=plotly_template)\\n\",\n",
    "    \"    if color_col not in f_df.columns:\\n\",\n",
    "    \"        color_col = 'model' # Fallback\\n\",\n",
    "    \"\\n\",\n",
    "    \"    fig = px.scatter_3d(f_df, x='turn_index', y=y_axis_col, z='drift_score',\\n\",\n",
    "    \"                        color=color_col, size='drift_score', opacity=0.7,\\n\",\n",
    "    \"                        hover_data=['filename', 'experiment_id', 'drift_notes', 'variant_id'],\\n\",\n",
    "    \"                        custom_data=[f_df.index], # Pass original DataFrame index\\n\",\n",
    "    \"                        color_continuous_scale=px.colors.sequential.Viridis if pd.api.types.is_numeric_dtype(f_df[color_col]) and f_df[color_col].nunique() > 1 else None,\\n\",\n",
    "    \"                        color_discrete_sequence=px.colors.qualitative.Plotly if not (pd.api.types.is_numeric_dtype(f_df[color_col]) and f_df[color_col].nunique() > 1) else None,\\n\",\n",
    "    \"                        title='3D Drift (Turn vs Y-Category vs Score)', template=plotly_template)\\n\",\n",
    "    \"    y_categories = sorted(f_df[y_axis_col].dropna().unique())\\n\",\n",
    "    \"    fig.update_layout(height=700, scene=dict(\\n\",\n",
    "    \"        xaxis_title='Turn Index',\\n\",\n",
    "    \"        yaxis_title=y_title,\\n\",\n",
    "    \"        zaxis_title='Drift Score',\\n\",\n",
    "    \"        yaxis=dict(type='category', categoryorder='array', categoryarray=y_categories)\\n\",\n",
    "    \"    ))\\n\",\n",
    "    \"    for trace in fig.data:\\n\",\n",
    "    \"        if isinstance(trace, go.Scatter3d):\\n\",\n",
    "    \"            trace.on_click(handle_point_click_v2_1)\\n\",\n",
    "    \"    return fig\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Statistics Function (Focused) ---\\n\",\n",
    "    \"def update_stats_output_v2_1(b=None):\\n\",\n",
    "    \"    f_df = get_filtered_df_v2_1()\\n\",\n",
    "    \"    if f_df.empty:\\n\",\n",
    "    \"        stats_output_v2_1.value = \\\"<i>No data for selected filters.</i>\\\"\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"\\n\",\n",
    "    \"    stats_html = f\\\"<h3>Filtered Data Statistics ({len(f_df)} rows):</h3>\\\"\\n\",\n",
    "    \"    stats_html += f\\\"<b>Avg Drift:</b> {f_df['drift_score'].mean():.3f} | <b>Median:</b> {f_df['drift_score'].median():.3f} | <b>StdDev:</b> {f_df['drift_score'].std():.3f}<br>\\\"\\n\",\n",
    "    \"    stats_html += f\\\"<b>Min Drift:</b> {f_df['drift_score'].min():.3f} | <b>Max Drift:</b> {f_df['drift_score'].max():.3f}<br>\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if 'model' in f_df.columns and 'sys_prompt_tag' in f_df.columns and \\\\\\n\",\n",
    "    \"       f_df[['model', 'sys_prompt_tag']].notna().all(axis=1).any():\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            avg_drift_model_sys = f_df.groupby(['model', 'sys_prompt_tag'])['drift_score'].mean().unstack()\\n\",\n",
    "    \"            if not avg_drift_model_sys.empty:\\n\",\n",
    "    \"                stats_html += \\\"<br><b>Avg Drift Score by Model and System Prompt:</b><br>\\\" + \\\\\\\n",
    "    \"                              avg_drift_model_sys.to_html(classes='table table-sm table-striped',\\n\",\n",
    "    \"                                                          float_format='{:.3f}'.format) # Corrected float_format\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            stats_html += f\\\"<br><i>Error generating model/sys_prompt stats: {e}</i>\\\"\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        stats_html += \\\"<br><i>Not enough data for Avg Drift by Model and System Prompt.</i>\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if 'parsed_drift_notes' in f_df.columns:\\n\",\n",
    "    \"        current_all_notes = Counter(tag for sublist in f_df['parsed_drift_notes'] for tag in sublist)\\n\",\n",
    "    \"        if current_all_notes:\\n\",\n",
    "    \"            stats_html += \\\"<br><b>Top 5 Drift Notes in Selection:</b><br>\\\"\\n\",\n",
    "    \"            for note, count in current_all_notes.most_common(5): stats_html += f\\\"- {note}: {count}<br>\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if 'parsed_containment_flags' in f_df.columns:\\n\",\n",
    "    \"        current_all_flags = Counter(tag for sublist in f_df['parsed_containment_flags'] for tag in sublist)\\n\",\n",
    "    \"        if current_all_flags:\\n\",\n",
    "    \"            stats_html += \\\"<br><b>Top 5 Containment Flags:</b><br>\\\"\\n\",\n",
    "    \"            for flag, count in current_all_flags.most_common(5): stats_html += f\\\"- {flag}: {count}<br>\\\"\\n\",\n",
    "    \"            \\n\",\n",
    "    \"    stats_output_v2_1.value = stats_html\\n\",\n",
    "    \"\\n\",\n",
    "    \"stats_button_v2_1.on_click(update_stats_output_v2_1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 5. Dashboard Update Logic and Display (V2.1 - Focused)\"\n",
    "   ],\n",
    "   \"metadata\": {}\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- Main Update Function (V2.1) ---\\n\",\n",
    "    \"def on_value_change_v2_1(*args):\\n\",\n",
    "    \"    f_df = get_filtered_df_v2_1()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with main_plot_output_v2_1.batch_update():\\n\",\n",
    "    \"        main_plot_output_v2_1.data = []\\n\",\n",
    "    \"        main_plot_output_v2_1.layout = {} \\n\",\n",
    "    \"        \\n\",\n",
    "    \"        selected_view = viz_type_dropdown_v2_1.value\\n\",\n",
    "    \"        fig = None\\n\",\n",
    "    \"        if selected_view == 'Drift Trajectory (Model & SysPrompt vs Turn)': fig = plot_drift_trajectory_focused(f_df)\\n\",\n",
    "    \"        elif selected_view == 'Drift Distribution (Model vs SysPrompt)': fig = plot_drift_distribution_focused(f_df)\\n\",\n",
    "    \"        elif selected_view == 'Drift Heatmap (Model & SysPrompt vs Turn)': fig = plot_drift_heatmap_focused(f_df)\\n\",\n",
    "    \"        elif selected_view == 'Drift Notes Frequency': fig = plot_notes_or_flags_freq_v2_1(f_df, \\\"dnote_\\\", \\\"parsed_drift_notes\\\", \\\"Drift Note\\\")\\n\",\n",
    "    \"        elif selected_view == 'Drift Notes vs Score': fig = plot_notes_or_flags_vs_score_v2_1(f_df, \\\"dnote_\\\", \\\"Drift Note\\\")\\n\",\n",
    "    \"        elif selected_view == 'Containment Flags Frequency': fig = plot_notes_or_flags_freq_v2_1(f_df, \\\"cflag_\\\", \\\"parsed_containment_flags\\\", \\\"Containment Flag\\\")\\n\",\n",
    "    \"        elif selected_view == 'Containment Flags vs Score': fig = plot_notes_or_flags_vs_score_v2_1(f_df, \\\"cflag_\\\", \\\"Containment Flag\\\")\\n\",\n",
    "    \"        elif selected_view == 'Text WordCloud (Model Output)': fig = plot_wordcloud_v2_1(f_df)\\n\",\n",
    "    \"        elif selected_view == '3D Drift Scatter (Turn, Model/SysPrompt, Score)': fig = plot_3d_drift_scatter_focused(f_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if fig:\\n\",\n",
    "    \"            main_plot_output_v2_1.add_traces(fig.data)\\n\",\n",
    "    \"            main_plot_output_v2_1.layout = fig.layout\\n\",\n",
    "    \"            main_plot_output_v2_1.layout.height = 700 \\n\",\n",
    "    \"            main_plot_output_v2_1.layout.template = plotly_template\\n\",\n",
    "    \"            \\n\",\n",
    "    \"    if viz_type_dropdown_v2_1.value not in ['Drift Trajectory (Model & SysPrompt vs Turn)', '3D Drift Scatter (Turn, Model/SysPrompt, Score)']:\\n\",\n",
    "    \"         detail_text_output_v2_1.value = \\\"<i>Detail view on click available for 'Drift Trajectory' and '3D Drift Scatter'.</i>\\\"\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"         detail_text_output_v2_1.value = \\\"<i>Click on a point to see details.</i>\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"# --- Observe Changes ---\\n\",\n",
    "    \"widgets_to_observe_v2_1 = [model_dropdown_v2_1, sys_prompt_dropdown_v2_1, usr_prompt_dropdown_v2_1,\\n\",\n",
    "    \"                           experiment_dropdown_v2_1, mode_dropdown_v2_1, variant_id_dropdown_v2_1, \\n\",\n",
    "    \"                           drift_slider_v2_1, turn_slider_v2_1, viz_type_dropdown_v2_1]\\n\",\n",
    "    \"if isinstance(dnote_filter_v2_1, widgets.SelectMultiple): widgets_to_observe_v2_1.append(dnote_filter_v2_1)\\n\",\n",
    "    \"if isinstance(cflag_filter_v2_1, widgets.SelectMultiple): widgets_to_observe_v2_1.append(cflag_filter_v2_1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for w in widgets_to_observe_v2_1:\\n\",\n",
    "    \"    w.observe(on_value_change_v2_1, names='value')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Dashboard Layout (V2.1 - Focused) ---\\n\",\n",
    "    \"controls_col1_v2_1 = widgets.VBox([model_dropdown_v2_1, sys_prompt_dropdown_v2_1, usr_prompt_dropdown_v2_1])\\n\",\n",
    "    \"controls_col2_v2_1 = widgets.VBox([experiment_dropdown_v2_1, mode_dropdown_v2_1, variant_id_dropdown_v2_1])\\n\",\n",
    "    \"controls_col3_sliders_v2_1 = widgets.VBox([drift_slider_v2_1, turn_slider_v2_1])\\n\",\n",
    "    \"controls_col4_multiselect_v2_1 = widgets.VBox([dnote_filter_v2_1, cflag_filter_v2_1])\\n\",\n",
    "    \"\\n\",\n",
    "    \"filters_area_v2_1 = widgets.HBox([controls_col1_v2_1, controls_col2_v2_1, controls_col3_sliders_v2_1, controls_col4_multiselect_v2_1])\\n\",\n",
    "    \"view_selector_area_v2_1 = widgets.HBox([viz_type_dropdown_v2_1])\\n\",\n",
    "    \"\\n\",\n",
    "    \"dashboard_layout_v2_1 = widgets.VBox([\\n\",\n",
    "    \"    dashboard_title_v2_1,\\n\",\n",
    "    \"    filters_area_v2_1,\\n\",\n",
    "    \"    view_selector_area_v2_1,\\n\",\n",
    "    \"    main_plot_output_v2_1,\\n\",\n",
    "    \"    widgets.HBox([detail_text_output_v2_1, \\n\",\n",
    "    \"                  widgets.VBox([stats_button_v2_1, stats_output_v2_1], layout=widgets.Layout(width='48%'))], \\n\",\n",
    "    \"                 layout=widgets.Layout(justify_content='space-between', width='100%'))\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Initial Display ---\\n\",\n",
    "    \"if not df.empty and 'drift_score' in df.columns: # Check if df is not empty AND has essential column\\n\",\n",
    "    \"    display(dashboard_layout_v2_1)\\n\",\n",
    "    \"    on_value_change_v2_1() \\n\",\n",
    "    \"    update_stats_output_v2_1()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    display(widgets.HTML(\\\"<h1>Drift Data Not Loaded or Malformed</h1><p>Cannot display dashboard. Please ensure 'per_turn_drift_v2.csv' is loaded correctly and contains necessary data like 'drift_score'.</p>\\\"))\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 6. Specific Sort: Drift Score per Turn between Models and System Prompts\\n\",\n",
    "    \"This is already covered by a few of the views:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1.  **'Drift Trajectory (Model & SysPrompt vs Turn)'**:\\n\",\n",
    "    \"    *   Directly plots `drift_score` vs. `turn_index`, with lines colored by `model` and styled by `sys_prompt_tag`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"2.  **'Drift Heatmap (Model & SysPrompt vs Turn)'**:\\n\",\n",
    "    \"    *   The `plot_drift_heatmap_focused` function groups by `['turn_index', 'model', 'sys_prompt_tag']` and can show this relationship.\\n\",\n",
    "    \"\\n\",\n",
    "    \"3.  **'Drift Distribution (Model vs SysPrompt)'**:\\n\",\n",
    "    \"    *   Shows distributions for `model` vs `sys_prompt_tag` combinations. Filter by a single turn using the slider for per-turn view.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Tabular data for this specific sort:**\"\n",
    "   ],\n",
    "   \"metadata\": {}\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if not df.empty and all(col in df.columns for col in ['model', 'sys_prompt_tag', 'turn_index', 'drift_score']):\\n\",\n",
    "    \"    # Average drift score per model, per system prompt, per turn\\n\",\n",
    "    \"    avg_drift_per_turn_model_sys = df.groupby(['model', 'sys_prompt_tag', 'turn_index'])['drift_score'].mean().reset_index()\\n\",\n",
    "    \"    print(\\\"\\\\nAverage Drift Score per Turn, Model, and System Prompt:\\\")\\n\",\n",
    "    \"    if not avg_drift_per_turn_model_sys.empty:\\n\",\n",
    "    \"        display(avg_drift_per_turn_model_sys.head(20))\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"No data after grouping for this view.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # To pivot this for easier comparison (e.g., turns as columns):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        pivot_avg_drift = avg_drift_per_turn_model_sys.pivot_table(\\n\",\n",
    "    \"            index=['model', 'sys_prompt_tag'], \\n\",\n",
    "    \"            columns='turn_index', \\n\",\n",
    "    \"            values='drift_score'\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        print(\\\"\\\\nPivoted Average Drift Score (Turns as Columns):\\\")\\n\",\n",
    "    \"        if not pivot_avg_drift.empty:\\n\",\n",
    "    \"            display(pivot_avg_drift)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(\\\"Pivoted table is empty - likely not enough data diversity for this shape.\\\")\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error creating pivoted table: {e}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Required columns for specific sort not found or DataFrame is empty.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 7. Conclusion\\n\",\n",
    "    \"This focused notebook removes `persona`, `scored`, and `temperature` filters and visualizations, \\n\",\n",
    "    \"and ensures that the core analysis of drift score per turn across models and system prompts\\n\",\n",
    "    \"is clearly achievable through the primary interactive views and tabular data.\"\n",
    "   ],\n",
    "   \"metadata\": {}\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Refined Monster Notebook (V2.1 Focused) processing complete!\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.4\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
