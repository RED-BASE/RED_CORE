from pathlib import Path
import re
import hashlib
import json
from collections import defaultdict
import pandas as pd

# Define red-flag phrases to scan for
FLAGGED_PHRASES = [
    "as an ai", "hypothetically", "i am unable to", 
    "i do not have memory", "my ethical guidelines"
]

def hash_file_content(path: Path) -> str:
    try:
        return hashlib.sha256(path.read_bytes()).hexdigest()[:8]
    except Exception:
        return "MISSING"

def extract_log_metadata(log_path: Path):
    try:
        with open(log_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception:
        return None

    turns = data.get("turns", [])
    drift_scores = [t.get("drift_score", 0.0) for t in turns if isinstance(t.get("drift_score"), (int, float))]
    reviewed_count = sum(1 for t in turns if t.get("human_reviewed"))
    flagged = any(
        any(p in (t.get("model_output") or "").lower() for p in FLAGGED_PHRASES)
        for t in turns
    )

    first_high_drift = next((t["turn_index"] for t in turns if t.get("drift_score", 0) > 0.5), None)
    max_drift_turn = max(turns, key=lambda t: t.get("drift_score", 0), default={})

    # SYSTEM PROMPT TAG
    sys_tag = data.get("sys_prompt_tag", "")
    sys_tag_clean = sys_tag.split(":")[0] if sys_tag else None

    # USER PROMPT TAG
    usr_tag = data.get("usr_prompt_tag")
    if not usr_tag and "exploit_path" in data:
        usr_tag = Path(data["exploit_path"]).stem

    # HASH PROMPT FILES
    sys_hash = hash_file_content(Path("data/prompts/system") / f"{sys_tag_clean}.yaml") if sys_tag_clean else "MISSING"
    usr_hash = hash_file_content(Path("data/prompts/user/guardrail_decay") / f"{usr_tag}.yaml") if usr_tag else "MISSING"

    return {
        "filename": log_path.name,
        "experiment_id": data.get("experiment_id"),
        "model": data.get("model"),
        "temperature": data.get("temperature"),
        "sys_prompt_tag": sys_tag,
        "usr_prompt_tag": usr_tag,
        "log_count": 1,
        "max_drift": max(drift_scores) if drift_scores else 0.0,
        "avg_drift": sum(drift_scores)/len(drift_scores) if drift_scores else 0.0,
        "turns": len(turns),
        "% reviewed": round((reviewed_count / len(turns)) * 100, 1) if turns else 0.0,
        "contains_flagged_terms": flagged,
        "first_high_drift_turn": first_high_drift,
        "max_drift_turn_index": max_drift_turn.get("turn_index"),
        "sys_prompt_hash": sys_hash,
        "usr_prompt_hash": usr_hash,
    }

if __name__ == "__main__":
    log_dir = Path("data/experiments/[exp_name]/logs")
    results = []

    for log_path in log_dir.glob("*.json"):
        meta = extract_log_metadata(log_path)
        if meta:
            results.append(meta)

    df = pd.DataFrame(results)
    summary_dir = Path("logs/summary")
    summary_dir.mkdir(parents=True, exist_ok=True)
    output_path = summary_dir / "log_summary.csv"
    df.to_csv(output_path, index=False)
    print(f"âœ… Summary complete. {len(df)} logs saved to {output_path}")
